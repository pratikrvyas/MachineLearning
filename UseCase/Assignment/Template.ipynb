{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "\n",
    "# to evaluate regression models\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# to evaluate classification models\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#######################################################\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import warnings # supress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's inspect the percentage of missing values in each variable\n",
    "data.isnull().mean().sort_values(ascending=True)\n",
    "data.isnull().sum()\n",
    "\n",
    "#missing value > 70%\n",
    "\n",
    "churn_data_missing=pd.DataFrame(churn_data.isna().mean().round(4) * 100)\n",
    "churn_data_missing.where(churn_data_missing[0] > 0.70).dropna()\n",
    "\n",
    "print(churn_data_missing)\n",
    "print(churn_data_missing.shape)\n",
    "\n",
    "\n",
    "\n",
    "####################### Categorical missing val #####################333\n",
    "## Categorical features which are missing\n",
    "features_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes=='O']\n",
    "\n",
    "for feature in features_nan:\n",
    "    print(\"{}: {}% missing values\".format(feature,np.round(dataset[feature].isnull().mean(),4)))\n",
    "    \n",
    "    \n",
    "## Replace missing value with a new label\n",
    "def replace_cat_feature(dataset,features_nan):\n",
    "    data=dataset.copy()\n",
    "    data[features_nan]=data[features_nan].fillna('Missing')\n",
    "    return data\n",
    "\n",
    "dataset=replace_cat_feature(dataset,features_nan)\n",
    "\n",
    "dataset[features_nan].isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "####################### Numeric missing val #####################333\n",
    "numerical_with_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes!='O']\n",
    "\n",
    "## We will print the numerical nan variables and percentage of missing values\n",
    "\n",
    "for feature in numerical_with_nan:\n",
    "    print(\"{}: {}% missing value\".format(feature,np.around(dataset[feature].isnull().mean(),4)))\n",
    "    \n",
    "    \n",
    "## Replacing the numerical Missing Values\n",
    "\n",
    "for feature in numerical_with_nan:\n",
    "    ## We will replace by using median since there are outliers\n",
    "    median_value=dataset[feature].median()\n",
    "    \n",
    "    ## create a new feature to capture nan values\n",
    "    dataset[feature+'nan']=np.where(dataset[feature].isnull(),1,0)\n",
    "    dataset[feature].fillna(median_value,inplace=True)\n",
    "    \n",
    "dataset[numerical_with_nan].isnull().sum()\n",
    "\n",
    "\n",
    "####################### Impute NA with Median #####################333\n",
    "# let's make a function to create 2 variables from Age:\n",
    "# one filling NA with median, and another one filling NA with zeroes\n",
    "\n",
    "def impute_na(df, variable, median):\n",
    "    df[variable+'_median'] = df[variable].fillna(median)\n",
    "    df[variable+'_zero'] = df[variable].fillna(0)\n",
    "\n",
    "\n",
    "median = X_train.Age.median()\n",
    "impute_na(X_train, 'Age', median)\n",
    "X_train.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename column / Drop Columns / Fill NA / Drop NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename column name \n",
    "df.rename(columns ={'aug_vbc_3g':'vbc_3g_8', 'jul_vbc_3g':'vbc_3g_7'}, inplace = True) \n",
    "\n",
    "\n",
    "## Drop columns\n",
    "df = df.drop(['circle_id' , 'HV_thrashhold'], axis=1)\n",
    "\n",
    "\n",
    "## object type columns\n",
    "df.select_dtypes(include=['object']).columns\n",
    "\n",
    "## Fill NA  and drop NA\n",
    "churn_data_missing.where(churn_data_missing[0] > 0.70).dropna()\n",
    "churn_data=churn_data.fillna(0)\n",
    "\n",
    "### remove one column from df\n",
    "df=df.loc[:,~df.columns.isin([\"mobile_number\"])]\n",
    "\n",
    "### group by\n",
    "X_train.groupby(['FireplaceQu'])['FireplaceQu'].count().sort_values(ascending=False).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking outliers at 25%, 50%, 75%, 90%, 95% and 99%\n",
    "churn_data_HV.select_dtypes(include=['int64','float64']).describe(percentiles=[.75, .90, .95, .99,0.999])\n",
    "\n",
    "################# outlier detection=IQR (inter quartile range ) ##################################\n",
    "\n",
    "churn_data_IQR=churn_data_HV.select_dtypes(include=['int64','float64'])\n",
    "\n",
    "Q1 = churn_data_IQR.quantile(0.10)\n",
    "Q3 = churn_data_IQR.quantile(0.90)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(IQR)\n",
    "\n",
    "thrashhold=1.5\n",
    "\n",
    "churn_data_IQR_outlier = churn_data_IQR[~((churn_data_IQR < (Q1 - thrashhold * IQR)) |(churn_data_IQR > (Q3 + thrashhold * IQR))).any(axis=1)]\n",
    "\n",
    "print(\"original count \" ,churn_data_HV.shape)\n",
    "print(\"After removing outlier\"  , churn_data_IQR_outlier.shape)\n",
    "\n",
    "\n",
    "################# outlier detection=  Z-score ##################################\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "churn_data_HV_o=churn_data_HV.select_dtypes(include=['int64','float64'])\n",
    "churn_data_HV_o=churn_data_HV_o.loc[:,~churn_data_HV_o.columns.isin([\"mobile_number\"])]\n",
    "\n",
    "z = np.abs(stats.zscore(churn_data_HV_o,axis=1))\n",
    "\n",
    "threshold = 3\n",
    "print(np.where(z > 3)\n",
    "      \n",
    "## remove outlier\n",
    "churn_data_zscore_outlier = churn_data_HV[(z < 3).all(axis=1)]\n",
    "\n",
    "print(\"original count \" ,churn_data_HV.shape)\n",
    "print(\"After removing outlier \" , churn_data_zscore_outlier.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling - MinMax / Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# StandardScaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# MinMaxScaler\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "cols=df_train.columns\n",
    "df_train[cols]=scaler.fit_transform(df_train[cols])\n",
    "\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label Encoder on Embarked Varibale\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df.Embarked = le.fit_transform(df.Embarked)\n",
    "df.head()\n",
    "\n",
    "## apply label encoding on text categorical variable.\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "categorical_text_var=[\"carbody\",\"enginelocation\",\"aspiration\",\"fueltype\",\"CarCompany\",\"doornumber\",\"drivewheel\",\"fuelsystem\", \"enginetype\"\n",
    ",\"cylindernumber\"]\n",
    "\n",
    "lab = preprocessing.LabelEncoder() \n",
    "cars[categorical_text_var]=cars[categorical_text_var].apply(lambda col: lab.fit_transform(col))\n",
    "cars[categorical_text_var].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## BOX plot #########################\n",
    "import seaborn as sns\n",
    "\n",
    "for col in churn_data_HV.select_dtypes(include=['int64','float64']).columns:\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    #sns.distplot(churn_data_HV[col])\n",
    "    sns.boxplot(x=churn_data_HV[col])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "################## Scatter plot- Co-Relation #########################      \n",
    "sns.pairplot(df)\n",
    "plt.show()\n",
    "\n",
    "################## HeatMap- Co-Relation ######################### \n",
    "plt.figure(figsize = (16, 10))\n",
    "sns.heatmap(df_train.corr(), annot = True, cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "################## Scatter plot #########################    \n",
    "\n",
    "cnt=0\n",
    "plt.figure(figsize=(20, 12))\n",
    "for x in selected_features:\n",
    "    plt.subplot(2,3,cnt+1)\n",
    "    plt.scatter(X_train[x] ,(y_train - y_train_predicted))\n",
    "    plt.xlabel(x, fontsize = 18)                         \n",
    "    plt.ylabel('Error', fontsize = 16)\n",
    "    cnt+=1\n",
    "plt.show()\n",
    "\n",
    "\n",
    "################## Bell curve #########################    \n",
    "\n",
    "for col in churn_data_HV.select_dtypes(include=['int64','float64']).columns:\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    sns.distplot(churn_data_HV[col])\n",
    "    #sns.boxplot(x=churn_data_HV[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    train_size=0.7,\n",
    "                                                    test_size = 0.3, random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold CV (using all the 13 variables)\n",
    "lm = LinearRegression()\n",
    "\n",
    "# create a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "scores = cross_val_score(lm, X_train, y_train, scoring='r2', cv=folds)\n",
    "scores\n",
    "# can tune other metrics, such as MSE\n",
    "scores = cross_val_score(lm, X_train, y_train, scoring='mean_squared_error', cv=5)\n",
    "scores\n",
    "\n",
    "##############################cross-validation scheme##############################\n",
    "\n",
    "# step-1: create a cross-validation scheme\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{'n_features_to_select': list(range(1, 14))}]\n",
    "\n",
    "\n",
    "# step-3: perform grid search\n",
    "# 3.1 specify model\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "rfe = RFE(lm)             \n",
    "\n",
    "# 3.2 call GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = rfe, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'r2', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "#3.3 fit the model\n",
    "model_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3.4 cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results\n",
    "\n",
    "\n",
    "#3.5 plotting cv results\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_test_score\"])\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('r-squared')\n",
    "plt.title(\"Optimal Number of Features\")\n",
    "plt.legend(['test score', 'train score'], loc='upper left')\n",
    "\n",
    "\n",
    "#3.6 final model\n",
    "n_features_optimal = 10\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "rfe = RFE(lm, n_features_to_select=n_features_optimal)             \n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "\n",
    "# predict prices of X_test\n",
    "y_pred = lm.predict(X_test)\n",
    "r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "\n",
    "# Load and split the data\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construct some pipelines\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('pca', PCA(n_components=2)),\n",
    "\t\t\t('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_svm = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('pca', PCA(n_components=2)),\n",
    "\t\t\t('clf', svm.SVC(random_state=42))])\n",
    "\t\t\t\n",
    "pipe_dt = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('pca', PCA(n_components=2)),\n",
    "\t\t\t('clf', tree.DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "# List of pipelines for ease of iteration\n",
    "pipelines = [pipe_lr, pipe_svm, pipe_dt]\n",
    "\t\t\t\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "pipe_dict = {0: 'Logistic Regression', 1: 'Support Vector Machine', 2: 'Decision Tree'}\n",
    "\n",
    "# Fit the pipelines\n",
    "for pipe in pipelines:\n",
    "\tpipe.fit(X_train, y_train)\n",
    "\n",
    "# Compare accuracies\n",
    "for idx, val in enumerate(pipelines):\n",
    "\tprint('%s pipeline test accuracy: %.3f' % (pipe_dict[idx], val.score(X_test, y_test)))\n",
    "\n",
    "# Identify the most accurate model on test data\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_pipe = ''\n",
    "for idx, val in enumerate(pipelines):\n",
    "\tif val.score(X_test, y_test) > best_acc:\n",
    "\t\tbest_acc = val.score(X_test, y_test)\n",
    "\t\tbest_pipe = val\n",
    "\t\tbest_clf = idx\n",
    "print('Classifier with best accuracy: %s' % pipe_dict[best_clf])\n",
    "\n",
    "# Save pipeline to file\n",
    "joblib.dump(best_pipe, 'best_pipeline.pkl', compress=1)\n",
    "print('Saved %s pipeline to file' % pipe_dict[best_clf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python script for confusion matrix creation. \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "actual = [1, 1, 0, 1, 0, 0, 1, 0, 0, 0] \n",
    "predicted = [1, 0, 0, 1, 0, 0, 1, 1, 1, 0] \n",
    "\n",
    "results = confusion_matrix(actual, predicted) \n",
    "\n",
    "print 'Confusion Matrix :'\n",
    "print(results) \n",
    "print 'Accuracy Score :',accuracy_score(actual, predicted) \n",
    "print 'Report : '\n",
    "print classification_report(actual, predicted) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
