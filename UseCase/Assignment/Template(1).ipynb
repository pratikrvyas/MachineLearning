{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing \n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing value > 70%\n",
    "\n",
    "churn_data_missing=pd.DataFrame(churn_data.isna().mean().round(4) * 100)\n",
    "churn_data_missing.where(churn_data_missing[0] > 0.70).dropna()\n",
    "\n",
    "print(churn_data_missing)\n",
    "print(churn_data_missing.shape)\n",
    "\n",
    "\n",
    "\n",
    "####################### Categorical missing val #####################333\n",
    "## Categorical features which are missing\n",
    "features_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes=='O']\n",
    "\n",
    "for feature in features_nan:\n",
    "    print(\"{}: {}% missing values\".format(feature,np.round(dataset[feature].isnull().mean(),4)))\n",
    "    \n",
    "    \n",
    "## Replace missing value with a new label\n",
    "def replace_cat_feature(dataset,features_nan):\n",
    "    data=dataset.copy()\n",
    "    data[features_nan]=data[features_nan].fillna('Missing')\n",
    "    return data\n",
    "\n",
    "dataset=replace_cat_feature(dataset,features_nan)\n",
    "\n",
    "dataset[features_nan].isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "####################### Numeric missing val #####################333\n",
    "numerical_with_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes!='O']\n",
    "\n",
    "## We will print the numerical nan variables and percentage of missing values\n",
    "\n",
    "for feature in numerical_with_nan:\n",
    "    print(\"{}: {}% missing value\".format(feature,np.around(dataset[feature].isnull().mean(),4)))\n",
    "    \n",
    "    \n",
    "## Replacing the numerical Missing Values\n",
    "\n",
    "for feature in numerical_with_nan:\n",
    "    ## We will replace by using median since there are outliers\n",
    "    median_value=dataset[feature].median()\n",
    "    \n",
    "    ## create a new feature to capture nan values\n",
    "    dataset[feature+'nan']=np.where(dataset[feature].isnull(),1,0)\n",
    "    dataset[feature].fillna(median_value,inplace=True)\n",
    "    \n",
    "dataset[numerical_with_nan].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename column / Drop Columns / Fill NA / Drop NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename column name \n",
    "df.rename(columns ={'aug_vbc_3g':'vbc_3g_8', 'jul_vbc_3g':'vbc_3g_7'}, inplace = True) \n",
    "\n",
    "\n",
    "## Drop columns\n",
    "df = df.drop(['circle_id' , 'HV_thrashhold'], axis=1)\n",
    "\n",
    "\n",
    "## object type columns\n",
    "df.select_dtypes(include=['object']).columns\n",
    "\n",
    "## Fill NA  and drop NA\n",
    "churn_data_missing.where(churn_data_missing[0] > 0.70).dropna()\n",
    "churn_data=churn_data.fillna(0)\n",
    "\n",
    "### remove one column from df\n",
    "df=df.loc[:,~df.columns.isin([\"mobile_number\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking outliers at 25%, 50%, 75%, 90%, 95% and 99%\n",
    "churn_data_HV.select_dtypes(include=['int64','float64']).describe(percentiles=[.75, .90, .95, .99,0.999])\n",
    "\n",
    "################# outlier detection=IQR (inter quartile range ) ##################################\n",
    "\n",
    "churn_data_IQR=churn_data_HV.select_dtypes(include=['int64','float64'])\n",
    "\n",
    "Q1 = churn_data_IQR.quantile(0.10)\n",
    "Q3 = churn_data_IQR.quantile(0.90)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(IQR)\n",
    "\n",
    "thrashhold=1.5\n",
    "\n",
    "churn_data_IQR_outlier = churn_data_IQR[~((churn_data_IQR < (Q1 - thrashhold * IQR)) |(churn_data_IQR > (Q3 + thrashhold * IQR))).any(axis=1)]\n",
    "\n",
    "print(\"original count \" ,churn_data_HV.shape)\n",
    "print(\"After removing outlier\"  , churn_data_IQR_outlier.shape)\n",
    "\n",
    "\n",
    "################# outlier detection=  Z-score ##################################\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "churn_data_HV_o=churn_data_HV.select_dtypes(include=['int64','float64'])\n",
    "churn_data_HV_o=churn_data_HV_o.loc[:,~churn_data_HV_o.columns.isin([\"mobile_number\"])]\n",
    "\n",
    "z = np.abs(stats.zscore(churn_data_HV_o,axis=1))\n",
    "\n",
    "threshold = 3\n",
    "print(np.where(z > 3)\n",
    "      \n",
    "## remove outlier\n",
    "churn_data_zscore_outlier = churn_data_HV[(z < 3).all(axis=1)]\n",
    "\n",
    "print(\"original count \" ,churn_data_HV.shape)\n",
    "print(\"After removing outlier \" , churn_data_zscore_outlier.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling - MinMax / Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# StandardScaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# MinMaxScaler\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "cols=df_train.columns\n",
    "df_train[cols]=scaler.fit_transform(df_train[cols])\n",
    "\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label Encoder on Embarked Varibale\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df.Embarked = le.fit_transform(df.Embarked)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "################## BOX plot #########################\n",
    "import seaborn as sns\n",
    "\n",
    "for col in churn_data_HV.select_dtypes(include=['int64','float64']).columns:\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    #sns.distplot(churn_data_HV[col])\n",
    "    sns.boxplot(x=churn_data_HV[col])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "################## Scatter plot- Co-Relation #########################      \n",
    "sns.pairplot(df)\n",
    "plt.show()\n",
    "\n",
    "################## HeatMap- Co-Relation ######################### \n",
    "plt.figure(figsize = (16, 10))\n",
    "sns.heatmap(df_train.corr(), annot = True, cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "################## Scatter plot #########################    \n",
    "\n",
    "cnt=0\n",
    "plt.figure(figsize=(20, 12))\n",
    "for x in selected_features:\n",
    "    plt.subplot(2,3,cnt+1)\n",
    "    plt.scatter(X_train[x] ,(y_train - y_train_predicted))\n",
    "    plt.xlabel(x, fontsize = 18)                         \n",
    "    plt.ylabel('Error', fontsize = 16)\n",
    "    cnt+=1\n",
    "plt.show()\n",
    "\n",
    "\n",
    "################## Bell curve #########################    \n",
    "\n",
    "for col in churn_data_HV.select_dtypes(include=['int64','float64']).columns:\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    sns.distplot(churn_data_HV[col])\n",
    "    #sns.boxplot(x=churn_data_HV[col])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(dataset,dataset['SalePrice'],test_size=0.1,random_state=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
